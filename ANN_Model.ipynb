{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "575TdM06OUnn",
        "outputId": "a1ca7bce-7dda-4d32-fb57-4ee3dc5015b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
            "0            842     0          2.2         0   1       0           7    0.6   \n",
            "1           1021     1          0.5         1   0       1          53    0.7   \n",
            "2            563     1          0.5         1   2       1          41    0.9   \n",
            "3            615     1          2.5         0   0       0          10    0.8   \n",
            "4           1821     1          1.2         0  13       1          44    0.6   \n",
            "\n",
            "   mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time  \\\n",
            "0        188        2  ...         20       756  2549     9     7         19   \n",
            "1        136        3  ...        905      1988  2631    17     3          7   \n",
            "2        145        5  ...       1263      1716  2603    11     2          9   \n",
            "3        131        6  ...       1216      1786  2769    16     8         11   \n",
            "4        141        2  ...       1208      1212  1411     8     2         15   \n",
            "\n",
            "   three_g  touch_screen  wifi  price_range  \n",
            "0        0             0     1            1  \n",
            "1        1             1     0            0  \n",
            "2        1             1     0            0  \n",
            "3        1             0     0            0  \n",
            "4        1             1     0            1  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/Mobile_Price_Classification-220531-204702.csv')\n",
        "\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "x=data.drop('price_range',axis=1)\n",
        "y=data['price_range']\n",
        "\n",
        "scaler =StandardScaler()\n",
        "x_scaled =scaler.fit_transform\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "uyE4jrPrO5d0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64,activation='relu',input_dim=x_train.shape[1]))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "# model.summery()\n",
        "\n",
        "model.fit(x_train,y_train,epochs=100,batch_size=32,validation_data=(x_test,y_test))\n",
        "\n",
        "loss,accuracy=model.evaluate(x_test,y_test)\n",
        "print(f'Test Loss:{loss},Test Accuracy:{accuracy}')\n",
        "\n",
        "model.save_weights('mobile_price_model.weights.h5')\n",
        "model.save('model.h5')\n",
        "\n",
        "test_loss,test_accuracy=model.evaluate(x_test,y_test)\n",
        "print(f'Test Loss:{test_loss},Test Accuracy:{test_accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfQpMUBrPzLI",
        "outputId": "ea9419fc-0977-426b-f496-503b3ec6b76d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5954 - loss: 25.5094 - val_accuracy: 0.5975 - val_loss: 6.3491\n",
            "Epoch 2/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6014 - loss: 6.1998 - val_accuracy: 0.6400 - val_loss: 3.6698\n",
            "Epoch 3/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5980 - loss: 3.5264 - val_accuracy: 0.6450 - val_loss: 3.1187\n",
            "Epoch 4/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6261 - loss: 3.0607 - val_accuracy: 0.6600 - val_loss: 3.0009\n",
            "Epoch 5/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6285 - loss: 2.7531 - val_accuracy: 0.6600 - val_loss: 1.8790\n",
            "Epoch 6/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6269 - loss: 2.4108 - val_accuracy: 0.6200 - val_loss: 1.9770\n",
            "Epoch 7/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6102 - loss: 2.8794 - val_accuracy: 0.6500 - val_loss: 2.2224\n",
            "Epoch 8/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6590 - loss: 2.1931 - val_accuracy: 0.5525 - val_loss: 3.1974\n",
            "Epoch 9/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 3.7798 - val_accuracy: 0.6875 - val_loss: 1.6369\n",
            "Epoch 10/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5839 - loss: 4.8002 - val_accuracy: 0.6225 - val_loss: 1.8532\n",
            "Epoch 11/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6457 - loss: 2.0389 - val_accuracy: 0.6125 - val_loss: 1.7969\n",
            "Epoch 12/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6452 - loss: 2.2206 - val_accuracy: 0.6000 - val_loss: 4.4403\n",
            "Epoch 13/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6169 - loss: 3.4669 - val_accuracy: 0.6675 - val_loss: 1.8057\n",
            "Epoch 14/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 1.3485 - val_accuracy: 0.6700 - val_loss: 1.5881\n",
            "Epoch 15/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6345 - loss: 2.1312 - val_accuracy: 0.6300 - val_loss: 2.7342\n",
            "Epoch 16/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6201 - loss: 2.2918 - val_accuracy: 0.6325 - val_loss: 1.4487\n",
            "Epoch 17/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 1.5500 - val_accuracy: 0.6725 - val_loss: 1.1630\n",
            "Epoch 18/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6176 - loss: 2.3021 - val_accuracy: 0.6250 - val_loss: 4.2102\n",
            "Epoch 19/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6221 - loss: 2.4022 - val_accuracy: 0.6600 - val_loss: 1.2973\n",
            "Epoch 20/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6585 - loss: 1.2469 - val_accuracy: 0.6700 - val_loss: 1.0971\n",
            "Epoch 21/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6453 - loss: 1.4733 - val_accuracy: 0.6000 - val_loss: 1.4948\n",
            "Epoch 22/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 1.6363 - val_accuracy: 0.6850 - val_loss: 2.2424\n",
            "Epoch 23/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6576 - loss: 1.9152 - val_accuracy: 0.6750 - val_loss: 1.4323\n",
            "Epoch 24/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6490 - loss: 1.8629 - val_accuracy: 0.6800 - val_loss: 2.4407\n",
            "Epoch 25/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6629 - loss: 1.9825 - val_accuracy: 0.6275 - val_loss: 4.5878\n",
            "Epoch 26/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6213 - loss: 3.0849 - val_accuracy: 0.7000 - val_loss: 1.3321\n",
            "Epoch 27/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6444 - loss: 1.6918 - val_accuracy: 0.6300 - val_loss: 1.1791\n",
            "Epoch 28/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6538 - loss: 1.1497 - val_accuracy: 0.6425 - val_loss: 0.9885\n",
            "Epoch 29/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 1.4545 - val_accuracy: 0.6700 - val_loss: 1.2113\n",
            "Epoch 30/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6691 - loss: 1.3891 - val_accuracy: 0.6350 - val_loss: 2.4217\n",
            "Epoch 31/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6283 - loss: 2.0905 - val_accuracy: 0.6875 - val_loss: 1.0916\n",
            "Epoch 32/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6320 - loss: 1.7264 - val_accuracy: 0.6625 - val_loss: 1.6467\n",
            "Epoch 33/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6637 - loss: 1.3644 - val_accuracy: 0.6850 - val_loss: 1.2216\n",
            "Epoch 34/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.9325 - val_accuracy: 0.4950 - val_loss: 4.8496\n",
            "Epoch 35/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6301 - loss: 2.1065 - val_accuracy: 0.6275 - val_loss: 2.2695\n",
            "Epoch 36/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6164 - loss: 1.8845 - val_accuracy: 0.6700 - val_loss: 1.4133\n",
            "Epoch 37/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6659 - loss: 1.4503 - val_accuracy: 0.6625 - val_loss: 2.1396\n",
            "Epoch 38/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6653 - loss: 1.1814 - val_accuracy: 0.6675 - val_loss: 0.8970\n",
            "Epoch 39/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6845 - loss: 0.9814 - val_accuracy: 0.5375 - val_loss: 2.0325\n",
            "Epoch 40/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6352 - loss: 1.7235 - val_accuracy: 0.6325 - val_loss: 2.7150\n",
            "Epoch 41/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6623 - loss: 1.4052 - val_accuracy: 0.6550 - val_loss: 1.2095\n",
            "Epoch 42/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6652 - loss: 1.4066 - val_accuracy: 0.6250 - val_loss: 4.3428\n",
            "Epoch 43/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6315 - loss: 2.0929 - val_accuracy: 0.6350 - val_loss: 1.1927\n",
            "Epoch 44/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6450 - loss: 1.6764 - val_accuracy: 0.6875 - val_loss: 1.1190\n",
            "Epoch 45/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6352 - loss: 1.4105 - val_accuracy: 0.6850 - val_loss: 1.2677\n",
            "Epoch 46/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6452 - loss: 2.0448 - val_accuracy: 0.6125 - val_loss: 1.8953\n",
            "Epoch 47/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6126 - loss: 2.1261 - val_accuracy: 0.5450 - val_loss: 3.0858\n",
            "Epoch 48/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6728 - loss: 1.5064 - val_accuracy: 0.6275 - val_loss: 1.1372\n",
            "Epoch 49/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6724 - loss: 1.0424 - val_accuracy: 0.6675 - val_loss: 0.9897\n",
            "Epoch 50/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6207 - loss: 2.3103 - val_accuracy: 0.6850 - val_loss: 1.0196\n",
            "Epoch 51/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6823 - loss: 0.9807 - val_accuracy: 0.5850 - val_loss: 1.2031\n",
            "Epoch 52/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 1.4266 - val_accuracy: 0.6600 - val_loss: 0.9575\n",
            "Epoch 53/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6459 - loss: 1.9744 - val_accuracy: 0.6350 - val_loss: 3.5739\n",
            "Epoch 54/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6410 - loss: 2.1706 - val_accuracy: 0.6750 - val_loss: 0.9056\n",
            "Epoch 55/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 1.5686 - val_accuracy: 0.6650 - val_loss: 1.0575\n",
            "Epoch 56/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6567 - loss: 1.6537 - val_accuracy: 0.6325 - val_loss: 1.5307\n",
            "Epoch 57/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6736 - loss: 1.1990 - val_accuracy: 0.5950 - val_loss: 1.2561\n",
            "Epoch 58/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6258 - loss: 2.0999 - val_accuracy: 0.5425 - val_loss: 2.4042\n",
            "Epoch 59/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6262 - loss: 1.7322 - val_accuracy: 0.6425 - val_loss: 3.0581\n",
            "Epoch 60/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6360 - loss: 1.9840 - val_accuracy: 0.6175 - val_loss: 1.3949\n",
            "Epoch 61/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6543 - loss: 1.4478 - val_accuracy: 0.6825 - val_loss: 0.9027\n",
            "Epoch 62/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6701 - loss: 1.2102 - val_accuracy: 0.6850 - val_loss: 1.7854\n",
            "Epoch 63/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6757 - loss: 1.1590 - val_accuracy: 0.6775 - val_loss: 0.9202\n",
            "Epoch 64/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6599 - loss: 1.1623 - val_accuracy: 0.6350 - val_loss: 1.1820\n",
            "Epoch 65/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6516 - loss: 1.2361 - val_accuracy: 0.6600 - val_loss: 1.0129\n",
            "Epoch 66/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6252 - loss: 1.9506 - val_accuracy: 0.6700 - val_loss: 2.2993\n",
            "Epoch 67/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6731 - loss: 1.4995 - val_accuracy: 0.6850 - val_loss: 1.1089\n",
            "Epoch 68/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6429 - loss: 1.3207 - val_accuracy: 0.6350 - val_loss: 1.8091\n",
            "Epoch 69/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6801 - loss: 1.3689 - val_accuracy: 0.6250 - val_loss: 1.0031\n",
            "Epoch 70/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6747 - loss: 1.0837 - val_accuracy: 0.6250 - val_loss: 0.8991\n",
            "Epoch 71/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6447 - loss: 1.0413 - val_accuracy: 0.6925 - val_loss: 1.7131\n",
            "Epoch 72/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 1.6416 - val_accuracy: 0.5775 - val_loss: 1.4902\n",
            "Epoch 73/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6380 - loss: 1.2348 - val_accuracy: 0.6625 - val_loss: 1.7317\n",
            "Epoch 74/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6727 - loss: 1.1689 - val_accuracy: 0.6700 - val_loss: 0.9413\n",
            "Epoch 75/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.8474 - val_accuracy: 0.6875 - val_loss: 0.9290\n",
            "Epoch 76/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6390 - loss: 1.3340 - val_accuracy: 0.6700 - val_loss: 1.0681\n",
            "Epoch 77/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6698 - loss: 1.1522 - val_accuracy: 0.5600 - val_loss: 1.4724\n",
            "Epoch 78/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6411 - loss: 1.3952 - val_accuracy: 0.7075 - val_loss: 1.2784\n",
            "Epoch 79/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 3.3266 - val_accuracy: 0.6925 - val_loss: 1.1482\n",
            "Epoch 80/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 1.3948 - val_accuracy: 0.6775 - val_loss: 0.8964\n",
            "Epoch 81/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6629 - loss: 1.4432 - val_accuracy: 0.6250 - val_loss: 2.0004\n",
            "Epoch 82/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5946 - loss: 2.2247 - val_accuracy: 0.5900 - val_loss: 1.7290\n",
            "Epoch 83/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6686 - loss: 1.2939 - val_accuracy: 0.6325 - val_loss: 3.0928\n",
            "Epoch 84/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6193 - loss: 2.2295 - val_accuracy: 0.6850 - val_loss: 1.0907\n",
            "Epoch 85/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 1.1329 - val_accuracy: 0.6725 - val_loss: 0.9250\n",
            "Epoch 86/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6619 - loss: 1.2710 - val_accuracy: 0.6850 - val_loss: 1.0082\n",
            "Epoch 87/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6668 - loss: 1.0595 - val_accuracy: 0.6925 - val_loss: 0.7694\n",
            "Epoch 88/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6659 - loss: 1.1242 - val_accuracy: 0.6750 - val_loss: 1.3644\n",
            "Epoch 89/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6904 - loss: 1.0010 - val_accuracy: 0.6200 - val_loss: 2.2560\n",
            "Epoch 90/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6726 - loss: 1.1865 - val_accuracy: 0.6975 - val_loss: 0.8925\n",
            "Epoch 91/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6515 - loss: 1.3763 - val_accuracy: 0.6775 - val_loss: 1.2067\n",
            "Epoch 92/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6848 - loss: 1.0511 - val_accuracy: 0.5850 - val_loss: 1.2866\n",
            "Epoch 93/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6420 - loss: 1.3969 - val_accuracy: 0.6875 - val_loss: 1.2287\n",
            "Epoch 94/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6728 - loss: 1.0594 - val_accuracy: 0.6825 - val_loss: 0.9210\n",
            "Epoch 95/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6512 - loss: 1.5047 - val_accuracy: 0.6850 - val_loss: 0.8821\n",
            "Epoch 96/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6978 - loss: 0.8100 - val_accuracy: 0.6425 - val_loss: 1.1455\n",
            "Epoch 97/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6856 - loss: 0.8194 - val_accuracy: 0.6550 - val_loss: 1.3538\n",
            "Epoch 98/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6556 - loss: 1.1141 - val_accuracy: 0.6775 - val_loss: 1.2503\n",
            "Epoch 99/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6900 - loss: 0.8018 - val_accuracy: 0.5300 - val_loss: 1.9737\n",
            "Epoch 100/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6620 - loss: 1.1142 - val_accuracy: 0.7225 - val_loss: 0.7513\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.7476 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss:0.7512951493263245,Test Accuracy:0.7225000262260437\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.7476 \n",
            "Test Loss:0.7512951493263245,Test Accuracy:0.7225000262260437\n"
          ]
        }
      ]
    }
  ]
}